{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLiG993Yxx3G",
    "outputId": "db87c969-dea7-4532-eff7-07ee16d589b6"
   },
   "source": [
    "# Ibtissam's LSTM-Attention Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLiG993Yxx3G",
    "outputId": "db87c969-dea7-4532-eff7-07ee16d589b6"
   },
   "source": [
    "## **Acknowledgment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLiG993Yxx3G",
    "outputId": "db87c969-dea7-4532-eff7-07ee16d589b6"
   },
   "source": [
    "- **Original source**: [*LSTM-Attention model.ipynb*](https://github.com/bibtissam/LSTM-Attention-FraudDetection/blob/main/LSTM-Attention%20model.ipynb)\n",
    "- **Model's Article**: [*\"Enhanced credit card fraud detection based on attention mechanism and LSTM deep model\", 2021*](https://doi.org/10.1186/s40537-021-00541-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Setting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASTEST_MODEL_NAME = 'model_2_Ibtissam_LSTM_acc'\n",
    "MODEL_PATH = 'architectures/'\n",
    "DATASET_PATH = 'dataset/'\n",
    "NEW_MODEL = True\n",
    "PERFORM_TRAINING = True\n",
    "SAVE_MODEL = True\n",
    "RANDOM_SEED = 42 # Set to `None` for the generator uses the current system time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running on `Binder`, then it is no need to set up the packages again\n",
    "# %pip install -r requirements.txt\n",
    "\n",
    "# ---OR---\n",
    "\n",
    "# %pip install tensorflow==2.10.1 numpy==1.26.4 pandas scikit-learn imblearn matplotlib seaborn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gRu9kpkYyztz"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import sklearn.metrics as metrique\n",
    "# from pandas import Series\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from matplotlib import pyplot\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.utils import np_utils\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from keras.models import Sequential\n",
    "# from keras.utils import np_utils\n",
    "# from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "# from keras.models import Sequential\n",
    "# from keras import backend as K, regularizers, Model, metrics\n",
    "# from keras.backend import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: `3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]`\n",
      "Base Python location: `C:\\Users\\LMT\\AppData\\Local\\Programs\\Python\\Python310`\n",
      "Current Environment location: `.venv_xai_fraud_detection`\n",
      "\n",
      "Tensorflow version: `2.10.1`\n",
      "CUDNN version: `64_8`\n",
      "CUDA version: `64_112`\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Lambda, LSTM, Dense, Embedding, Dropout,Input, Attention, Layer, Concatenate, Permute, Dot, Multiply, Flatten\n",
    "from tensorflow.keras import backend as K, regularizers, Model, metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import os\n",
    "import utils\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Relevant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.kaggle.com/api/v1/datasets/download/kartik2112/fraud-detection/fraudTrain.csv\n",
      "File `dataset/fraudTrain.csv` already exists.\n",
      "URL: https://www.kaggle.com/api/v1/datasets/download/kartik2112/fraud-detection/fraudTest.csv\n",
      "File `dataset/fraudTest.csv` already exists.\n"
     ]
    }
   ],
   "source": [
    "utils.download_dataset_from_kaggle('fraudTrain.csv')\n",
    "utils.download_dataset_from_kaggle('fraudTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(os.path.join(DATASET_PATH, 'fraudTrain.csv'), index_col=0)\n",
    "data_test = pd.read_csv(os.path.join(DATASET_PATH, 'fraudTest.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Credit Card Fraud Dataset Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Field # | Field Name | Description |\n",
    "|---------|------------|-------------|\n",
    "| 1 | **trans_date_trans_time** | Date and time when transaction occurred |\n",
    "| 2 | **cc_num** | Credit card number of customer |\n",
    "| 3 | **merchant** | Name of merchant where transaction occurred |\n",
    "| 4 | **category** | Category of merchant (e.g., retail, food, etc.) |\n",
    "| 5 | **amt** | Amount of transaction |\n",
    "| 6 | **first** | First name of credit card holder |\n",
    "| 7 | **last** | Last name of credit card holder |\n",
    "| 8 | **gender** | Gender of credit card holder |\n",
    "| 9 | **street** | Street address of credit card holder |\n",
    "| 10 | **city** | City of credit card holder |\n",
    "| 11 | **state** | State of credit card holder |\n",
    "| 12 | **zip** | ZIP code of credit card holder |\n",
    "| 13 | **lat** | Latitude location of credit card holder |\n",
    "| 14 | **long** | Longitude location of credit card holder |\n",
    "| 15 | **city_pop** | Population of credit card holder's city |\n",
    "| 16 | **job** | Occupation of credit card holder |\n",
    "| 17 | **dob** | Date of birth of credit card holder |\n",
    "| 18 | **trans_num** | Transaction number |\n",
    "| 19 | **unix_time** | UNIX timestamp of transaction |\n",
    "| 20 | **merch_lat** | Latitude location of merchant |\n",
    "| 21 | **merch_long** | Longitude location of merchant |\n",
    "| 22 | **is_fraud** | Target class indicating whether transaction is fraudulent (1) or legitimate (0) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1289169, 1: 7506})\n"
     ]
    }
   ],
   "source": [
    "# Generate and plot imbalanced classification dataset\n",
    "# summarize class distribution\n",
    "counter = Counter(data_train['is_fraud'])\n",
    "print(counter)\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    "\trow_ix = np.where(data_train['is_fraud'] == label)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = utils.feature_engineering(data_train)\n",
    "data_test = utils.feature_engineering(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "t7l5EpLY0IqL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal-Encoding is applied for `['merchant', 'category', 'gender', 'age_group']`\n",
      "SMOTE is applied\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, data_train, transformations_train = utils.pre_processing(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578338, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal-Encoding is applied for `['merchant', 'category', 'gender', 'age_group']`\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test, data_test, transformations_test = utils.pre_processing(data_test, isTestSet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OaLUwRhPPhW",
    "outputId": "170cccab-ded4-4110-e701-3d103902a590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555719, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "if NEW_MODEL:\n",
    "    inputs = Input((X_train.shape[1],))  # Original 2D input (samples, features)\n",
    "    reshaped = Lambda(lambda x: tf.expand_dims(x, axis=1))(inputs)  # Add time dimension\n",
    "    att_in_1=LSTM(50, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(reshaped)\n",
    "    att_in_2=LSTM(50, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(att_in_1)\n",
    "    att_out=attention()(att_in_2)\n",
    "    outputs=Dense(1, activation='sigmoid', trainable=True)(att_out)\n",
    "    model=Model(inputs, outputs, name='model_2_Ibtissam_LSTM')\n",
    "else:\n",
    "    model = utils.load_models(LASTEST_MODEL_NAME) # Continue training previous trained model if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "86/86 [==============================] - 13s 79ms/step - loss: 0.5946 - accuracy: 0.7174 - val_loss: 0.4998 - val_accuracy: 0.9539\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.4853 - accuracy: 0.7711 - val_loss: 0.4153 - val_accuracy: 0.9448\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 7s 86ms/step - loss: 0.4495 - accuracy: 0.7998 - val_loss: 0.3766 - val_accuracy: 0.9494\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 8s 97ms/step - loss: 0.4322 - accuracy: 0.8143 - val_loss: 0.3582 - val_accuracy: 0.9526\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 8s 94ms/step - loss: 0.4162 - accuracy: 0.8256 - val_loss: 0.3413 - val_accuracy: 0.9572\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 8s 91ms/step - loss: 0.3967 - accuracy: 0.8334 - val_loss: 0.3285 - val_accuracy: 0.9635\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 8s 98ms/step - loss: 0.3782 - accuracy: 0.8387 - val_loss: 0.3247 - val_accuracy: 0.9675\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 8s 90ms/step - loss: 0.3635 - accuracy: 0.8486 - val_loss: 0.3223 - val_accuracy: 0.9521\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 8s 91ms/step - loss: 0.3528 - accuracy: 0.8585 - val_loss: 0.3198 - val_accuracy: 0.9311\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 7s 86ms/step - loss: 0.3447 - accuracy: 0.8626 - val_loss: 0.3167 - val_accuracy: 0.9216\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 10s 113ms/step - loss: 0.3390 - accuracy: 0.8647 - val_loss: 0.3199 - val_accuracy: 0.9147\n",
      "Epoch 12/100\n",
      "23/86 [=======>......................] - ETA: 5s - loss: 0.3355 - accuracy: 0.8661"
     ]
    }
   ],
   "source": [
    "if PERFORM_TRAINING:\n",
    "    epochs = 100\n",
    "    batch_size=30000\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=4,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs,batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUAD5FIS3Z1I"
   },
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict_binary = np.round(y_predict).astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_postfix = f'_acc{accuracy_score(y_test, y_predict_binary)*100:.0f}'\n",
    "\n",
    "if model.name.find('_acc') != -1:\n",
    "    model._name = model.name[:model.name.find('_acc')] + acc_postfix\n",
    "else:\n",
    "    model._name = model.name + acc_postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "utils.save_predictions(model.name, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "ZFXwEl17ES7A",
    "outputId": "92daea33-c2f5-4354-ee72-eb9e4759e176"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "labels = ['Normal','Fraud']\n",
    "\n",
    "plot_confusion_matrix(cm=confusion_matrix(y_true=y_test, y_pred=y_predict_binary), classes=labels, title='LSTM-Attention', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiN2cjwX4Dzp",
    "outputId": "86ee0069-2931-41b4-bbb3-90a6a3940a21"
   },
   "outputs": [],
   "source": [
    "utils.get_model_metrics_df(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLCxQgUtIV6A",
    "outputId": "ac8b52c7-0d1c-476b-f5d2-396947e122b7"
   },
   "outputs": [],
   "source": [
    "if SAVE_MODEL:\n",
    "    model.save(os.path.join(MODEL_PATH, model.name))\n",
    "    # model.save(os.path.join(MODEL_PATH, model.name}.h5'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv_xai_fraud_detection",
   "language": "python",
   "name": ".venv_xai_fraud_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
